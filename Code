
#install.packages("moments")
#install.packages("gmodels")
#install.packages("vcd")
#install.packages("mixtools")

library(moments)
library(gmodels)
library(vcd)
library(mixtools)

mortgage <- read.csv("mortgage.csv")

summary(mortgage)

#initialize some empty vectors to calculate statsitics of default_time:
Frequency <- numeric()
Percent <- numeric()
Cumulative_Frequency <- numeric()
Cumulative_Percent <- numeric()

#extrect the unique values of default:
default_indicator <- unique(mortgage$default_time)

#calculate cumulative frequency and percentage

for (i in 1:2){
  temp <- subset(mortgage, default_time == default_indicator[i])
  Frequency[i] <- length(temp$default_time)
  Percent[i] <- round(Frequency[i] /nrow(mortgage),4)*100
  if (i == 1){
    Cumulative_Frequency[i] <- Frequency[i] 
    Cumulative_PErcentage <- Percent[i]
    }
    else{
      Cumulative_Frequency[i] <- Frequency[i-1] +Frequncy[i]
      Cumulative_PErcentage <- Percent[i-1] + Percent[i]
      }
}


#store them in a dataframe and print:

results <- cbind.data.frame(default_indicator, Frequency, Percent, Cumulative_Frequency, Cumulative_Percent)
colnames(results) <- c("default_indicator", "Frequency", "Percent", "Cumulative_Frequency", "Cumulative_Percent")
print(results)




################

location measures!

Q-Q Plot!

Crosstables!

Joint emprical distributions!


################


#Data Preprocessing

#######

# Credit Scoring

hmeq <- read.csv("hmeq.csv")
install.packages("pROC")
require(pROC)

hmeq_omit <-na.omit(hmeq)
hmeq_omit$JOB <- as.factor(hmeq_omit$JOB)
hmeq_omit$REASON <- as.factor(hmeq_omit$REASON)


#use glm and start with intercept-only-model and full-model and use selct to choose the variables

hmeq_null <- glm(BAD ~ 1, data = hmeq_omit, family = binomial(link = "logit"))

hmeq_full <- glm(BAD ~ ., data = hmeq_omit, family = binomial(link = "logit"))


step(hmeq_null, scope = list(upper= hmeq_full), direction = "both", test= "Chisq", 
     data = hmeq_omit, k=2, trace = F)
#setting k=2 gives AIC

# choose the model according to step results:
# hmeq_final <- 

# take the summary of the model
#summary(hmeq_final)
#area under the curve:
#auc(hmeq_omit$BAD, hmeq_final$fitted.values)

#auc(hmeq_omit$BAD, hmeq_full$fitted.values)
#auc(hmeq_omit$BAD, hmeq_null$fitted.values)



#to see the ratios of the estimates
exp(cbind(-coef(hmeq_full), -confint(hmeq_full)))
# neeed to transform exponential form and adjust the sign

################

# Probabilitites of Default
#Discreate time hazard models:


install.packages("aod")
install.packages("Hmisc")
install.packages("gmodels")
install.packages("ordinal")
require(aod)
require(Hmisc)
require(gmodels)
require(ordinal)

linear_model <- lm(default_time ~ FICO_orig_time + LTV_orig_time + gdp_time, data = mortgage)

summary(linear_model)
anova(linear_model)

#Probit Model
#Maximum Likelihood

probit_model <- glm(default_time ~ FICO_orig_time+ LTV_time + gdp_time, 
                    family = binomial(link = "probit"), data= mortgage)
summary(probit_model)



# calculate AIC and BIC and 2LogL, to compare the models:

AIC_probit <- probit_model$aic
AIC_probit_null <- probit_model_null$aic


BIC_probit <- BIC(probit_model)
BIC_probit_null <- BIC(probit_model_null)

#deviance gives 2LogL

dev_probit <- probit_model$deviance
dev_probit_null <- probit_model_null$deviance

#summary table with values:
#table <- as.data.frame(matrix(c(AIC..., )))




#LR and Wald Tests:
LR <- probit_model$null.deviance - probit_model$deviance
pval_LR <- dchisq(LR, df= 3)

wald <- wald.test(coef(probit_model),Sigma=vcov(probit_model),Terms = 2:4)
pval_wald <- 1 - pchisq(wald$result$chi2[1], df=3)

#make table:

#...





#Calibration of probit models:

default_mean <- mean(mortgage$default_time, na.rm=T)
PD_mean <- mean(probit_model$fitted)

#make a table:

means <- as.data.frame(c(default_mean, PD_mean), row.names = c("default", "fitted pd")
colnames(means) <- c(mean)
print(means)



      
     
    
  
